#!/usr/bin/bash

source config.sh

nargs=$#

domgi=F
doblat=F
doncbi=F
doensembl=F
domirbase=F
domerge=F
docat=F
doexome=F
dodistrib=F
doagr=F

until [ -z "$1" ]  # Until all parameters used up . . .
do
    case "$1" in
    mgi)
	domgi=T
        ;;
    blat)
	doblat=T
        ;;
    ncbi)
	doncbi=T
        ;;
    ensembl)
	doensembl=T
        ;;
    mirbase)
	domirbase=T
        ;;
    merge)
	domerge=T
        ;;
    cat)
	docat=T
        ;;
    exome)
	doexome=T
        ;;
    dist*)
	dodistrib=T
        ;;
    agr)
	doagr=T
        ;;
    *)
        echo "Unrecognized option:" $1
	exit -1
    esac
    shift
done


########

logit "================================================================================="
logit "Starting refresh..." 

#######

function writeHeader {
    provider=$1
    file=$2
    url=$3
    ofile=$4

    cat > ${ofile} <<ENDHEADER
# ----------------------------------
# ${provider}
# File: `basename ${file}`
# File url: ${url}
# File downloaded on: `stat -c "%y" ${file}`
# Header info:
`head -100 ${file} | grep "^#" | grep -v "gff-version\|sequence-region\|###"`
# 
ENDHEADER
}

#######

function refreshProvider {
    provider=$1
    url=$2
    prepCmd=$3
    #
    extension="${url##*.}"
    #
    downloaded=${DATADIR}/${provider}.gff
    dprofile=${DATADIR}/${provider}.counts.txt
    prepped=${WORKINGDIR}/${provider}.gff
    pprofile=${WORKINGDIR}/${provider}.counts.txt
    splitpattern=${provider}.chr%s.gff
    splitpattern2=${WORKINGDIR}/${provider}.chr*.gff
    headerfile=${WORKINGDIR}/${provider}.header
    #


    logit "Downloading ${provider}: $url"
    if [ ${extension} = "gz" ]; then
	${CURL} ${url} 2>> ${LOGFILE} | ${GUNZIP} > ${downloaded} 2>> ${LOGFILE}
	checkExit
    else
	${CURL} ${url} > ${downloaded} 2>> ${LOGFILE}
	checkExit
    fi

    logit "Counting $provider downloaded..."
    ${COUNTCMD} ${downloaded} > ${dprofile} 2>> ${LOGFILE}
    checkExit

    logit "Prepping ${provider}..."
    $prepCmd < ${downloaded} > ${prepped} 2>> ${LOGFILE}
    checkExit

    logit "Splitting..."
    ${SPLITCMD} -t "${splitpattern}" < ${prepped} 2>> ${LOGFILE}
    checkExit

    logit "Writing header file..."
    writeHeader ${provider} ${downloaded} ${url} ${headerfile}
    checkExit

    logit "Counting ${provider} after prep..."
    ${COUNTCMD} ${splitpattern2} > ${pprofile} 2>> ${LOGFILE}
    checkExit

    return 0
}

########
# MGI
if [ $nargs -eq 0 -o $domgi == T ]; then
    # Queries MGI data. Writes genes and pseudogenes into gff3 file. Each has Dbxrefs containing
    # any provider model ids. Downstream merging will be directed by this data.
    logit "Prepping mgi ..."
    ${PYTHON} ${BIN}/mgiPrep.py 2>> ${LOGFILE} > ${WORKINGDIR}/mgi.gff
    checkExit
    ${SPLITCMD} -t "mgi.chr%s.gff" < ${WORKINGDIR}/mgi.gff
    checkExit

    logit "Writing header file..."
    # Naming the MGI header file "0" to ensure it come first
    cat > ${WORKINGDIR}/0.header <<END1
#
# MGI.gff3
# Date: `date`
# Taxonid: 10090
# Genome build: GRCm38
#
# The MGI gff3 file is generated by merging information from multiple sources.
# Gene nomenclature, identifiers, and cross references come from MGI.
# Gene models come from NCBI, ENSEMBL, and miRBase. Others may be added.
# Using the cross references in the MGI data, the provider models are merged
# with the MGI data. Each model in the result file comprises a hierarchy in which
# the MGI gene is the root and the provider models hang off, each transcript being 
# a branch off the root.
# Finally, for genes that do not have a model from at least one provider,
# we add 'ersatz' models by BLAT'ing gene sequences against the genome.
#
# The following lists information about each gene model provider: the file,
# its modification date, its URL, and selected header lines.
#
END1
    checkExit

    logit "Counting mgi features..."
    ${COUNTCMD} ${WORKINGDIR}/mgi.chr*.gff > ${WORKINGDIR}/mgi.counts.txt
    checkExit
fi

########
# BLAT models
if [ $nargs -eq 0 -o $doblat == T ]; then
    # Computes Blat'ed models for MGI genes that don't have models but do have good enough
    # sequences. The sequences are blatted against the mouse genome, and the best scoring
    # hits are made into models. 
    logit "Generating blat models..."
    ${BIN}/blatRefresh 2>> ${LOGFILE} > ${WORKINGDIR}/blat.gff
    checkExit

    ${SPLITCMD} -t "blat.chr%s.gff" < ${WORKINGDIR}/blat.gff
    checkExit

    logit "Counting blat models ..."
    ${COUNTCMD} ${WORKINGDIR}/blat.chr*.gff > ${WORKINGDIR}/blat.counts.txt
    checkExit
fi

########
# Refresh providers
if [ $nargs -eq 0 -o $doncbi == T ]; then
    # NCBI
    refreshProvider "ncbi" "${NCBIurl}" "${NCBIprep}"
fi

if [ $nargs -eq 0 -o $domirbase == T ]; then
    # miRBase
    refreshProvider "mirbase" "${MIRurl}" "${MIRprep}"
fi

if [ $nargs -eq 0 -o $doensembl == T ]; then
    # ENSEMBL
    refreshProvider "ensembl" "${ENSEMBLurl}" "${ENSEMBLprep}"
fi

########
# MERGE phase
if [ $nargs -eq 0 -o $domerge == T ]; then
    for i in "${CHRS[@]}"
    do : 
	logit
	logit "Merging chr${i}..."
	${PYTHON} ${BIN}/merge.py ${WORKINGDIR}/*.chr${i}.gff > ${WORKINGDIR}/chr${i}.gff 2>> ${LOGFILE}
	checkExit
    done
fi

########
# Concatenation phase
if [ $nargs -eq 0 -o $docat == T ]; then
    logit "Catting files..."
    echo '##gff-version 3' > ${WORKINGDIR}/MGI.gff3
    cat ${WORKINGDIR}/*.header >> ${WORKINGDIR}/MGI.gff3 2>> ${LOGFILE}
    cat ${WORKINGDIR}/chr*.gff >> ${WORKINGDIR}/MGI.gff3 2>> ${LOGFILE}

    logit "Running acceptance tests..."
    ${BIN}/acceptance.sh ${WORKINGDIR}/MGI.gff3 2>> ${LOGFILE}
    checkExit

    logit "Generating sample file..."
    ${BIN}/sample.sh < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.sample.gff3 2>> ${LOGFILE}
    checkExit

    # Generate feature type profile
    logit "Generating feature type profile..."
    ${COUNTCMD} < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.counts.txt 2>> ${LOGFILE}
    checkExit
fi

########
# EXOME phase
if [ $nargs -eq 0 -o $doexome == T ]; then
    logit "Creating MGI exome file..."
    ${PYTHON} ${BIN}/exome.py < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.exome.gff3 2>> ${LOGFILE}
    checkExit
fi

########
# AGR phase
if [ $nargs -eq 0 -o $doagr == T ]; then
    logit "Generating GFF3 file for AGR..."
    ${PYTHON} ${BIN}/trimForAgr.py < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.agr.gff3 2>> ${LOGFILE}
    checkExit

    logit "Running acceptance tests..."
    ${BIN}/acceptance.sh ${WORKINGDIR}/MGI.agr.gff3 2>> ${LOGFILE}
    checkExit
fi

########
# DISTRIB phase
if [ $nargs -eq 0 -o $dodistrib == T ]; then
    function distrib {
	#
	filename=$(basename "$1")		# e.g. MGI.exome.gff3
	extension="${filename##*.}"		# .gff3
	filenameNoExt="${filename%.*}"		# MGI.exome
	distfile=${DISTRIBDIR}/${filename}	# /path/to/dist/MGI.exome.gff3
	datestampedname=${filenameNoExt}.${DATESTAMP2}.${extension} # MGI.exome.20170922.gff3
	monthlyfile=${MONTHLYDIR}/${datestampedname}  # /path/to/monthly/MGI.exome.20170922.gff3
	annualname=${filenameNoExt}.${YEAR}.${extension} # MGI.exome.2017.gff3
	annualfile=${ARCHIVEDIR}/annual/${annualname} # /path/to/annuals/MGI.exome.2017.gff3

	#
	logit "Creating monthly: ${monthlyfile}"
	${CP} $1 ${monthlyfile}
	checkExit

	#
	if [ ! -e ${annualfile} ]; then
	    logit "Creating annual: ${annualfile}"
	    ${CP} $1 ${annualfile}
	    checkExit
	fi

	#
	logit "Creating symlink: ${distfile} -> ${monthlyfile}"
	${RM} -f ${distfile}
	${LN} -s ${monthlyfile} ${distfile}
	checkExit

	# 
	logit "Checking archive..."
	# list of files in the monthly archive older that the age limit:
	oldfiles=(`${FIND} ${MONTHLYDIR}/* -maxdepth 0 -mtime +${ARCHIVEAGELIMIT} `)
	if [ ${#oldfiles[@]} -gt 0 ]; then
	    logit "Deleting ${#oldfiles[@]} archive files: ${oldfiles[*]}"
	    ${RM} ${oldfiles[*]}
	    checkExit
	fi
    }
    distrib ${WORKINGDIR}/MGI.gff3
    distrib ${WORKINGDIR}/MGI.agr.gff3 
    distrib ${WORKINGDIR}/MGI.exome.gff3
    checkExit
fi

########
logit "Refresh finished. No errors detected."
