#!/usr/bin/bash

# https://stackoverflow.com/questions/59895/getting-the-source-directory-of-a-bash-script-from-within
export DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && cd ".." && pwd )"
source ${DIR}/Configuration

nargs=$#

domgi=F
doblat=F
doncbi=F
doensembl=F
domirbase=F
domerge=F
docat=F
doexome=F
dodistrib=F
doagr=F
donothing=F
nocounts=F

until [ -z "$1" ]  # Until all parameters used up . . .
do
    case "$1" in
    -c)
	shift
	echo "Sourcing config file:" $1
	source $1
	nargs=$((nargs-2))
	;;
    -n)
        donothing=T
	;;
    -N)
        nocounts=T
	nargs=$((nargs-1))
	;;
    mgi)
	domgi=T
        ;;
    blat)
	doblat=T
        ;;
    ncbi)
	doncbi=T
        ;;
    ensembl)
	doensembl=T
        ;;
    mirbase)
	domirbase=T
        ;;
    merge)
	domerge=T
        ;;
    cat)
	docat=T
        ;;
    exome)
	doexome=T
        ;;
    dist*)
	dodistrib=T
        ;;
    agr)
	doagr=T
        ;;
    *)
        echo "Unrecognized option:" $1
	exit -1
    esac
    shift
done

source ${DIR}/bin/config.sh

echo "Data directory:" $DATADIR
echo "Work directory:" $WORKINGDIR
echo "Dist directory:" $DISTRIBDIR
echo "Logging to: " ${LOGFILE}
#

if [ $donothing == T ]; then
    echo "Doing nothing."
    exit 0
fi

# ---------------------
${TOUCH} ${LOGFILE}

# ---------------------
${MKDIR} -p ${DATADIR}
${MKDIR} -p ${WORKINGDIR}
${MKDIR} -p ${DISTRIBDIR}
${MKDIR} -p ${ARCHIVEDIR}
${MKDIR} -p ${MONTHLYDIR}
${MKDIR} -p ${ANNUALDIR}

########
# truncate log file
> ${LOGFILE}
##
if [ $nargs -eq 0 ]; then
   rm -fr ${WORKINGDIR}/*
fi
#
logit "================================================================================="
logit "This is the MGI GFF3 pipeline."
logit "Starting refresh." 
logit "Data directory:" $DATADIR
logit "Work directory:" $WORKINGDIR
logit "Dist directory:" $DISTRIBDIR

#######

function writeHeader {
    provider=$1
    file=$2
    url=$3
    ofile=$4

    cat > ${ofile} <<ENDHEADER
# ----------------------------------
# ${provider}
# File: `basename ${file}`
# File url: ${url}
# File downloaded on: `stat -c "%y" ${file}`
# Header info:
`head -100 ${file} | grep "^#" | grep -v "gff-version\|sequence-region\|###"`
# 
ENDHEADER
}

#######

function refreshProvider {
    provider=$1
    url=$2
    prepCmd=$3
    #
    extension="${url##*.}"
    #
    downloaded=${DATADIR}/${provider}.gff
    dprofile=${DATADIR}/${provider}.counts.txt
    prepped=${WORKINGDIR}/${provider}.gff
    pprofile=${WORKINGDIR}/${provider}.counts.txt
    splitpattern=${provider}.chr%s.gff
    splitpattern2=${WORKINGDIR}/${provider}.chr*.gff
    headerfile=${WORKINGDIR}/${provider}.header
    #


    logit "Downloading ${provider}: $url to $downloaded"
    if [ ${extension} = "gz" ]; then
	#
	curl "${url}" > ${DATADIR}/wtf.gz 2>>  ${LOGFILE}
	checkExit
	#
	logit "Uncompressing..."
	# For some completely mysterious reason, gzip complains that it cannot
	# find file "gzip.gz". No idea where this name is coming from, and the
	# actual decompress happens just fine.
	# Therefore we will redirect the error to /dev/null and skip the checkExit step.
	gunzip -c "${DATADIR}/wtf.gz" > "${downloaded}" 2> /dev/null
	#checkExit
    else
	${CURL} ${url} > ${downloaded} 2>> ${LOGFILE}
	checkExit
    fi

    if [ ${nocounts} = "F" ]; then
        logit "Counting $provider downloaded..."
        ${COUNTCMD} ${downloaded} > ${dprofile} 2>> ${LOGFILE}
        checkExit
    fi

    logit "Prepping ${provider}..."
    $prepCmd < ${downloaded} > ${prepped} 2>> ${LOGFILE}
    checkExit

    logit "Splitting..."
    ${SPLITCMD} -t "${splitpattern}" < ${prepped} 2>> ${LOGFILE}
    checkExit

    logit "Writing header file..."
    writeHeader ${provider} ${downloaded} ${url} ${headerfile}
    checkExit

    if [ ${nocounts} = "F" ]; then
        logit "Counting ${provider} after prep..."
        ${COUNTCMD} ${splitpattern2} > ${pprofile} 2>> ${LOGFILE}
        checkExit
    fi

    return 0
}

########
# MGI
if [ $nargs -eq 0 -o $domgi == T ]; then
    # Queries MGI data. Writes genes and pseudogenes into gff3 file. Each has Dbxrefs containing
    # any provider model ids. Downstream merging will be directed by this data.
    logit "Prepping mgi ..."
    ${PYTHON} ${BIN}/mgiPrep.py 2>> ${LOGFILE} > ${WORKINGDIR}/mgi.gff
    checkExit
    #
    logit "Downloading SO terms..."
    ${CURL} "${SO_URL}" 2>> ${LOGFILE} > ${SO_TERM_FILE}

    logit "Writing header file..."
    # Naming the MGI header file "0" to ensure it come first
    cat > ${WORKINGDIR}/0.header <<END1
#
# MGI.gff3
# Date: `date`
# Taxonid: 10090
# Genome build: GRCm38
#
# The MGI gff3 file is generated by merging information from multiple sources.
# Gene nomenclature, identifiers, and cross references come from MGI.
# Gene models come from NCBI, ENSEMBL, and miRBase. Others may be added.
# Using the cross references in the MGI data, the provider models are merged
# with the MGI data. Each model in the result file comprises a hierarchy in which
# the MGI gene is the root and the provider models hang off, each transcript being 
# a branch off the root.
# Finally, for genes that do not have a model from at least one provider,
# we add 'ersatz' models by BLAT'ing gene sequences against the genome.
#
# The following lists information about each gene model provider: the file,
# its modification date, its URL, and selected header lines.
#
END1
    checkExit

    logit "Counting mgi features..."
    ${COUNTCMD} ${WORKINGDIR}/mgi.gff > ${WORKINGDIR}/mgi.counts.txt
    checkExit
fi

########
# Refresh providers
if [ $nargs -eq 0 -o $doncbi == T ]; then
    # NCBI
    refreshProvider "ncbi" "${NCBIurl}" "${NCBIprep}"
fi

if [ $nargs -eq 0 -o $domirbase == T ]; then
    # miRBase
    refreshProvider "mirbase" "${MIRurl}" "${MIRprep}"
fi

if [ $nargs -eq 0 -o $doensembl == T ]; then
    # ENSEMBL
    refreshProvider "ensembl" "${ENSEMBLurl}" "${ENSEMBLprep}"
fi

########
# MERGE phase for provider models. Merges models for same gene from different provider.
if [ $nargs -eq 0 -o $domerge == T ]; then
    for i in "${CHRS[@]}"
    do : 
	logit
	logit "Merging chr${i}..."
	logit "${PYTHON} ${BIN}/merge.py ${WORKINGDIR}/mgi.gff ${WORKINGDIR}/*.chr${i}.gff > ${WORKINGDIR}/chr${i}.gff 2>> ${LOGFILE}"
	${PYTHON} ${BIN}/merge.py ${WORKINGDIR}/mgi.gff ${WORKINGDIR}/*.chr${i}.gff > ${WORKINGDIR}/chr${i}.gff 2>> ${LOGFILE}
	checkExit
    done
fi

########
# BLAT models. Must run after all provider data has been processed so that we know
# who got a model and who didn't.
if [ $nargs -eq 0 -o $doblat == T ]; then
    # Computes Blat'ed models for MGI genes that don't have models but do have good enough
    # sequences. The sequences are blatted against the mouse genome, and the best scoring
    # hits are made into models. 
    logit "Generating blat models..."
    ${BIN}/blatRefresh 2>> ${LOGFILE} > ${WORKINGDIR}/blat.gff
    checkExit
fi

########
# Concatenation phase
if [ $nargs -eq 0 -o $docat == T ]; then
    logit "Catting files..."

    # start with header lines for MGI.gff3
    echo '##gff-version 3' > ${WORKINGDIR}/MGI.gff3
    cat ${WORKINGDIR}/*.header >> ${WORKINGDIR}/MGI.gff3 2>> ${LOGFILE}

    # cat chr*.gff files for provider models
    files=`ls ${WORKINGDIR}/chr*.gff | sort -V` 
    logit "cat ${files}"
    cat ${files} > ${WORKINGDIR}/provider.gff 2>> ${LOGFILE}

    # Merge provider and blatted models
    ${PYTHON} ${BIN}/gffMerge.py ${WORKINGDIR}/provider.gff ${WORKINGDIR}/blat.gff >> ${WORKINGDIR}/MGI.gff3
    
    logit "Running acceptance tests..."
    ${BIN}/acceptance.sh ${WORKINGDIR}/MGI.gff3 2>> ${LOGFILE}
    checkExit

    logit "Generating sample file..."
    ${BIN}/sample.sh < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.sample.gff3 2>> ${LOGFILE}
    checkExit

    # Generate feature type profile
    logit "Generating feature type profile..."
    ${COUNTCMD} < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.counts.txt 2>> ${LOGFILE}
    checkExit
fi

########
# EXOME phase
if [ $nargs -eq 0 -o $doexome == T ]; then
    logit "Creating MGI exome file..."
    ${PYTHON} ${BIN}/exome.py < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.exome.gff3 2>> ${LOGFILE}
    checkExit
fi

########
# AGR phase
if [ $nargs -eq 0 -o $doagr == T ]; then
    logit "Generating GFF3 file for AGR..."
    ${PYTHON} ${BIN}/trimForAgr.py < ${WORKINGDIR}/MGI.gff3 > ${WORKINGDIR}/MGI.agr.gff3 2>> ${LOGFILE}
    checkExit

    logit "Running acceptance tests..."
    ${BIN}/acceptance.sh ${WORKINGDIR}/MGI.agr.gff3 2>> ${LOGFILE}
    checkExit
fi

########
# DISTRIB phase
if [ $nargs -eq 0 -o $dodistrib == T ]; then
    function distrib {
	#
	filename=$(basename "$1")		# e.g. MGI.exome.gff3
	extension="${filename##*.}"		# .gff3
	filenameNoExt="${filename%.*}"		# MGI.exome
	datestampedname=${filenameNoExt}.${DATESTAMP2}.${extension} # MGI.exome.20170922.gff3
	monthlyname=${filenameNoExt}.${YEARMONTH}.${extension} # MGI.exome.201709.gff3
	annualname=${filenameNoExt}.${YEAR}.${extension} # MGI.exome.2017.gff3
	#
	distfile=${DISTRIBDIR}/${filename}.gz	            # /path/to/dist/MGI.exome.gff3.gz
	monthlyfile=${MONTHLYDIR}/${monthlyname}.gz     # /path/to/monthly/MGI.exome.20170922.gff3.gz
	annualfile=${ANNUALDIR}/${annualname}.gz    # /path/to/annuals/MGI.exome.2017.gff3.gz
	#
	logit "Creating monthly: ${monthlyfile} from input file $1"
	gzip -c $1 > ${monthlyfile}
	#checkExit

	#
	if [ ! -e ${annualfile} ]; then
	    logit "Creating annual: ${annualfile}"
	    ${CP} ${monthlyfile} ${annualfile}
	    checkExit
	fi

	#
	logit "Creating symlink: ${distfile} -> ${monthlyfile}"
	${RM} -f ${distfile}
	${LN} -s ${monthlyfile} ${distfile}
	checkExit

	# 
	logit "Checking archive..."
	# list of files in the monthly archive older that the age limit:
	oldfiles=(`${FIND} ${MONTHLYDIR}/* -maxdepth 0 -mtime +${ARCHIVEAGELIMIT} `)
	if [ ${#oldfiles[@]} -gt 0 ]; then
	    logit "Deleting ${#oldfiles[@]} archive files: ${oldfiles[*]}"
	    ${RM} ${oldfiles[*]}
	    checkExit
	fi
    }
    distrib ${WORKINGDIR}/MGI.gff3
    distrib ${WORKINGDIR}/MGI.agr.gff3 
    distrib ${WORKINGDIR}/MGI.exome.gff3
    checkExit
fi

########
logit "Refresh finished. No errors detected."
